# awesome-reasoning-models

# Research Papers

## Thinking Techniques

- [ https://arxiv.org/abs/2201.11903 ](Chain-of-Thought Prompting Elicits Reasoning in Large Language Models)
- [https://arxiv.org/abs/2305.10601](Tree of Thoughts: Deliberate Problem Solving with Large Language Models)
- [https://arxiv.org/abs/2404.15758](Let's Think Dot by Dot: Hidden Computation in Transformer Language Models)
- [https://arxiv.org/abs/2310.02226](Think before you speak: Training Language Models With Pause Tokens)
- [https://arxiv.org/abs/2402.05201](The Effect of Sampling Temperature on Problem Solving in Large Language Models)
- [https://arxiv.org/abs/2502.18600v2](Chain of Draft: Thinking Faster by Writing Less)

## Scaling Test-Time Compute

- [https://arxiv.org/abs/2407.21787](Large Language Monkeys: Scaling Inference Compute with Repeated Sampling)
- [https://arxiv.org/abs/2303.05510](Planning with Large Language Models for Code Generation)
- [https://arxiv.org/abs/2305.20050](Let's Verify Step by Step)
- [https://arxiv.org/abs/2406.03816](ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search)
- [https://arxiv.org/abs/2406.06592](Improve Mathematical Reasoning in Language Models by Automated Process Supervision)
- [https://arxiv.org/abs/2211.14275](Solving math word problems with process- and outcome-based feedback)
- [https://arxiv.org/abs/2408.03314](Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters)
- [https://arxiv.org/abs/2408.00724](Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models)
- [https://arxiv.org/abs/2501.19393](s1: Simple test-time scaling)
- [https://arxiv.org/abs/2502.06703](Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling)
- [https://arxiv.org/pdf/2502.20339](Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners)
- [https://arxiv.org/abs/2502.03387](LIMO: Less is More for Reasoning)
